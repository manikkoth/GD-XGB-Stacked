{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in e:\\new folder\\lib\\site-packages\n",
      "Requirement already satisfied: scikit-learn in e:\\new folder\\lib\\site-packages (from sklearn)\n",
      "Requirement already satisfied: joblib>=0.11 in e:\\new folder\\lib\\site-packages (from scikit-learn->sklearn)\n",
      "Requirement already satisfied: scipy>=0.17.0 in e:\\new folder\\lib\\site-packages (from scikit-learn->sklearn)\n",
      "Requirement already satisfied: numpy>=1.11.0 in e:\\new folder\\lib\\site-packages (from scikit-learn->sklearn)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using Decision tree as a non-paramteric method to create heuristic rules for classification and regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#benefits of using a decision tree\n",
    "#1. simple to understand and interpret the results\n",
    "#2. Tree structure, which represents the rules can be visualized\n",
    "#3. less data manipulation, transformation or normalization\n",
    "#4. less costly algorithm\n",
    "#5. handle both numerical and categorical data\n",
    "#6. multinomial problem: multiclass can be handles easily\n",
    "#7. validate the model easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9580420222262995"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(.38)*np.log2(0.38)+(-(0.62)*np.log2(0.62)) #base entropy 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log2(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9849072905154983"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for branch where emabrek = C\n",
    "-(.55)*np.log2(0.55)+(-(0.45)*np.log2(0.45))\n",
    "#for branch where emabrek = S\n",
    "-(.43)*np.log2(0.43)+(-(0.57)*np.log2(0.57))\n",
    "#for branch where emabrek = Q\n",
    "-(.43)*np.log2(0.43)+(-(0.57)*np.log2(0.57))\n",
    "#for branch where emabrek = B\n",
    "0\n",
    "weithed_entropy = ((168/884)*(-(.55)*np.log2(0.55)+(-(0.45)*np.log2(0.45)))) + ((70/884) * (-(.43)*np.log2(0.43)+(-(0.57)*np.log2(0.57)))) + ((644/884)*(-(.43)*np.log2(0.43)+(-(0.57)*np.log2(0.57))))\n",
    "weithed_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F1= 0.2\n",
    "F2 = -0.2\n",
    "F3 = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Maximum variance\n",
    "# Gini Coefficient\n",
    "# Entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.026865268289198774"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Informaion_gain = (-(.38)*np.log2(0.38)+(-(0.62)*np.log2(0.62))) - weithed_entropy\n",
    "Informaion_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.584819511673234"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-(.333)*np.log2(0.333)+(-(0.333)*np.log2(0.333))+(-(0.333)*np.log2(0.333)) #base entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# How to decide, which variable to be placed at the root node\n",
    "# Ans: compare the information gain by putting each variable at the root node\n",
    "# the variable that gives maximum information gain need to be selected\n",
    "\n",
    "# Information Gain = Entropy at base - Weighted Entropy at the node after the split\n",
    "\n",
    "# How to select the brances\n",
    "\n",
    "# How long you can expand the decision tree (max_depth)\n",
    "# Ans:\n",
    "# conditions to stop the decision tree\n",
    "# if all the samples in a node belong to same class\n",
    "# if all the features are already part of the tree\n",
    "# if all the samples entered the tree model\n",
    "\n",
    "\n",
    "# what is stopping criteria to terminate a tree\n",
    "# if all the samples in a node belong to same class\n",
    "# if all the features are already part of the tree\n",
    "# if all the samples entered the tree model\n",
    "\n",
    "# if i expand the tree, what are the limitations\n",
    "# model ovefit, train accuracy will be different from test accuracy\n",
    "\n",
    "# how to identify right fit for the tree\n",
    "# a balance between train and test\n",
    "\n",
    "# how to prune the tree\n",
    "# put conditions, min sample, max_depth, min leaf, delta chnage in IG\n",
    "\n",
    "# validation of a tree\n",
    "# k-fold cross validation can be used to prune the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "print (iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.DecisionTreeClassifier() # tree initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree1 = tree.DecisionTreeClassifier()\n",
    "tree1.fit(iris.data,iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree1.score(iris.data,iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01333333, 0.        , 0.56405596, 0.42261071])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree1.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.325"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13/40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tree pruning conditions\n",
    "\n",
    "#1. if all the samples in a leaf node belong to one specific class\n",
    "#2. if all the samples absorbed in the model\n",
    "#3. if all the variables are entered into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classification criteria\n",
    "\n",
    "#1. Gini Impurity Index : Sum(Pmk*(1-Pmk))\n",
    "# m = 3 (Iris Dataset)\n",
    "# 1,2,3.......K-1 number of levels in a target variable\n",
    "# k= number of samples for each class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2. Cross Entropy: Sum(-Pmk*log(Pmk))\n",
    "# m = 3 (Iris Dataset)\n",
    "# 1,2,3.......K-1 number of levels in a target variable\n",
    "# k= number of samples for each class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3. Misclassification Approach: 1-max(Pmk)\n",
    "# m = 3 (Iris Dataset)\n",
    "# 1,2,3.......K-1 number of levels in a target variable\n",
    "# k= number of samples for each class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n = 150\n",
    "# Setosa = 50\n",
    "# P(setosa,samples) = 50/150 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data',header=None,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1     2     3     4    5     6     7     8     9     10    11    12  \\\n",
       "0   1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29  5.64  1.04  3.92   \n",
       "1   1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28  4.38  1.05  3.40   \n",
       "2   1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81  5.68  1.03  3.17   \n",
       "3   1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18  7.80  0.86  3.45   \n",
       "4   1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82  4.32  1.04  2.93   \n",
       "\n",
       "     13  \n",
       "0  1065  \n",
       "1  1050  \n",
       "2  1185  \n",
       "3  1480  \n",
       "4   735  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Target','Alcohol','Malic acid','Ash','Alcalinity of ash ','Magnesium',' Total phenols',\n",
    "             'Flavanoids','Nonflavanoid phenols','Proanthocyanins','Color intensity','Hue','diluted wines','Proline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target  Alcohol  Malic acid   Ash  Alcalinity of ash   Magnesium  \\\n",
       "0       1    14.23        1.71  2.43                15.6        127   \n",
       "1       1    13.20        1.78  2.14                11.2        100   \n",
       "2       1    13.16        2.36  2.67                18.6        101   \n",
       "3       1    14.37        1.95  2.50                16.8        113   \n",
       "4       1    13.24        2.59  2.87                21.0        118   \n",
       "\n",
       "    Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0            2.80        3.06                  0.28             2.29   \n",
       "1            2.65        2.76                  0.26             1.28   \n",
       "2            2.80        3.24                  0.30             2.81   \n",
       "3            3.85        3.49                  0.24             2.18   \n",
       "4            2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  diluted wines  Proline  \n",
       "0             5.64  1.04           3.92     1065  \n",
       "1             4.38  1.05           3.40     1050  \n",
       "2             5.68  1.03           3.17     1185  \n",
       "3             7.80  0.86           3.45     1480  \n",
       "4             4.32  1.04           2.93      735  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Alcohol\n",
    " \t2) Malic acid\n",
    " \t3) Ash\n",
    "\t4) Alcalinity of ash  \n",
    " \t5) Magnesium\n",
    "\t6) Total phenols\n",
    " \t7) Flavanoids\n",
    " \t8) Nonflavanoid phenols\n",
    " \t9) Proanthocyanins\n",
    "\t10)Color intensity\n",
    " \t11)Hue\n",
    " \t12)OD280/OD315 of diluted wines\n",
    " \t13)Proline     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data.shape # input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print iris.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.feature_names # getting the feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target.shape # target variable or dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytree = tree.DecisionTreeClassifier()\n",
    "mytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytree = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "mytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt1 = mytree.fit(iris.data, iris.target)\n",
    "dt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0115876 , 0.0115876 , 0.64544598, 0.33137881])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt1.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1.fit(iris.data, iris.target)\n",
    "tree.export_graphviz(dt1,out_file='None')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.export_graphviz(dt1,out_file='tree.dot')\n",
    "dotfile = open(\"tree.dot\", 'w')\n",
    "tree.export_graphviz(dt1, out_file = dotfile, feature_names = iris.feature_names)\n",
    "dotfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_d = tree.export_graphviz(dt1,out_file='Decision Tree')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree\n",
    "iris = load_iris()\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"iris.dot\", 'w') as f:\n",
    "    f = tree.export_graphviz(clf, out_file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.unlink('iris.dot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dot_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(clf, out_file='Decision Tree', \n",
    "                         feature_names=iris.feature_names,  \n",
    "                         class_names=iris.target_names,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydotplus\n",
      "  Downloading https://files.pythonhosted.org/packages/60/bf/62567830b700d9f6930e9ab6831d6ba256f7b0b730acb37278b0ccdffacf/pydotplus-2.0.2.tar.gz (278kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.1 in c:\\users\\vipin\\anaconda3\\lib\\site-packages (from pydotplus) (2.3.0)\n",
      "Building wheels for collected packages: pydotplus\n",
      "  Running setup.py bdist_wheel for pydotplus: started\n",
      "  Running setup.py bdist_wheel for pydotplus: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\vipin\\AppData\\Local\\pip\\Cache\\wheels\\35\\7b\\ab\\66fb7b2ac1f6df87475b09dc48e707b6e0de80a6d8444e3628\n",
      "Successfully built pydotplus\n",
      "Installing collected packages: pydotplus\n",
      "Successfully installed pydotplus-2.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "#graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydotplus in e:\\new folder\\lib\\site-packages\n",
      "Requirement already satisfied: pyparsing>=2.0.1 in e:\\new folder\\lib\\site-packages (from pydotplus)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: msgpack in c:\\users\\vipin\\anaconda3\\lib\\site-packages (0.5.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install msgpack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# three methods determine the importance of features\n",
    "# 1. mean decrease in gini coefficient\n",
    "# 2. informtion gain -cross entropy\n",
    "# 3. variance based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt1.score(iris.data,iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree for regression based problems\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "regressor = DecisionTreeRegressor(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(boston.data, boston.target,test_size=0.20,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (404,), (102, 13), (102,))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,Y_train.shape,X_test.shape,Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=0, splitter='best')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DecisionTreeRegressor in module sklearn.tree.tree object:\n",
      "\n",
      "class DecisionTreeRegressor(BaseDecisionTree, sklearn.base.RegressorMixin)\n",
      " |  DecisionTreeRegressor(criterion='mse', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, presort=False)\n",
      " |  \n",
      " |  A decision tree regressor.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <tree>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  criterion : string, optional (default=\"mse\")\n",
      " |      The function to measure the quality of a split. Supported criteria\n",
      " |      are \"mse\" for the mean squared error, which is equal to variance\n",
      " |      reduction as feature selection criterion and minimizes the L2 loss\n",
      " |      using the mean of each terminal node, \"friedman_mse\", which uses mean\n",
      " |      squared error with Friedman's improvement score for potential splits,\n",
      " |      and \"mae\" for the mean absolute error, which minimizes the L1 loss\n",
      " |      using the median of each terminal node.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |         Mean Absolute Error (MAE) criterion.\n",
      " |  \n",
      " |  splitter : string, optional (default=\"best\")\n",
      " |      The strategy used to choose the split at each node. Supported\n",
      " |      strategies are \"best\" to choose the best split and \"random\" to choose\n",
      " |      the best random split.\n",
      " |  \n",
      " |  max_depth : int or None, optional (default=None)\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int, float, optional (default=2)\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a fraction and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int, float, optional (default=1)\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a fraction and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, optional (default=0.)\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_features : int, float, string or None, optional (default=None)\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, then consider `max_features` features at each split.\n",
      " |      - If float, then `max_features` is a fraction and\n",
      " |        `int(max_features * n_features)` features are considered at each\n",
      " |        split.\n",
      " |      - If \"auto\", then `max_features=n_features`.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`.\n",
      " |  \n",
      " |  max_leaf_nodes : int or None, optional (default=None)\n",
      " |      Grow a tree with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_decrease : float, optional (default=0.)\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  min_impurity_split : float, (default=1e-7)\n",
      " |      Threshold for early stopping in tree growth. A node will split\n",
      " |      if its impurity is above the threshold, otherwise it is a leaf.\n",
      " |  \n",
      " |      .. deprecated:: 0.19\n",
      " |         ``min_impurity_split`` has been deprecated in favor of\n",
      " |         ``min_impurity_decrease`` in 0.19. The default value of\n",
      " |         ``min_impurity_split`` will change from 1e-7 to 0 in 0.23 and it\n",
      " |         will be removed in 0.25. Use ``min_impurity_decrease`` instead.\n",
      " |  \n",
      " |  presort : bool, optional (default=False)\n",
      " |      Whether to presort the data to speed up the finding of best splits in\n",
      " |      fitting. For the default settings of a decision tree on large\n",
      " |      datasets, setting this to true may slow down the training process.\n",
      " |      When using either a smaller dataset or a restricted depth, this may\n",
      " |      speed up the training.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  feature_importances_ : array of shape = [n_features]\n",
      " |      The feature importances.\n",
      " |      The higher, the more important the feature.\n",
      " |      The importance of a feature is computed as the\n",
      " |      (normalized) total reduction of the criterion brought\n",
      " |      by that feature. It is also known as the Gini importance [4]_.\n",
      " |  \n",
      " |  max_features_ : int,\n",
      " |      The inferred value of max_features.\n",
      " |  \n",
      " |  n_features_ : int\n",
      " |      The number of features when ``fit`` is performed.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  tree_ : Tree object\n",
      " |      The underlying Tree object. Please refer to\n",
      " |      ``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n",
      " |      :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\n",
      " |      for basic usage of these attributes.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data and\n",
      " |  ``max_features=n_features``, if the improvement of the criterion is\n",
      " |  identical for several splits enumerated during the search of the best\n",
      " |  split. To obtain a deterministic behaviour during fitting,\n",
      " |  ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  DecisionTreeClassifier\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  .. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n",
      " |  \n",
      " |  .. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification\n",
      " |         and Regression Trees\", Wadsworth, Belmont, CA, 1984.\n",
      " |  \n",
      " |  .. [3] T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical\n",
      " |         Learning\", Springer, 2009.\n",
      " |  \n",
      " |  .. [4] L. Breiman, and A. Cutler, \"Random Forests\",\n",
      " |         https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_boston\n",
      " |  >>> from sklearn.model_selection import cross_val_score\n",
      " |  >>> from sklearn.tree import DecisionTreeRegressor\n",
      " |  >>> boston = load_boston()\n",
      " |  >>> regressor = DecisionTreeRegressor(random_state=0)\n",
      " |  >>> cross_val_score(regressor, boston.data, boston.target, cv=10)\n",
      " |  ...                    # doctest: +SKIP\n",
      " |  ...\n",
      " |  array([ 0.61..., 0.57..., -0.34..., 0.41..., 0.75...,\n",
      " |          0.07..., 0.29..., 0.33..., -1.42..., -1.77...])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DecisionTreeRegressor\n",
      " |      BaseDecisionTree\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, criterion='mse', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, presort=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      " |      Build a decision tree regressor from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The training input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like, shape = [n_samples] or [n_samples, n_outputs]\n",
      " |          The target values (real numbers). Use ``dtype=np.float64`` and\n",
      " |          ``order='C'`` for maximum efficiency.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples] or None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      X_idx_sorted : array-like, shape = [n_samples, n_features], optional\n",
      " |          The indexes of the sorted training input samples. If many tree\n",
      " |          are grown on the same dataset, this allows the ordering to be\n",
      " |          cached between trees. If None, the data will be sorted here.\n",
      " |          Don't use this parameter unless you know what to do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseDecisionTree:\n",
      " |  \n",
      " |  apply(self, X, check_input=True)\n",
      " |      Returns the index of the leaf that each sample is predicted as.\n",
      " |      \n",
      " |      .. versionadded:: 0.17\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array_like, shape = [n_samples,]\n",
      " |          For each datapoint x in X, return the index of the leaf x\n",
      " |          ends up in. Leaves are numbered within\n",
      " |          ``[0; self.tree_.node_count)``, possibly with gaps in the\n",
      " |          numbering.\n",
      " |  \n",
      " |  decision_path(self, X, check_input=True)\n",
      " |      Return the decision path in the tree\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse csr array, shape = [n_samples, n_nodes]\n",
      " |          Return a node indicator matrix where non zero elements\n",
      " |          indicates that the samples goes through the nodes.\n",
      " |  \n",
      " |  get_depth(self)\n",
      " |      Returns the depth of the decision tree.\n",
      " |      \n",
      " |      The depth of a tree is the maximum distance between the root\n",
      " |      and any leaf.\n",
      " |  \n",
      " |  get_n_leaves(self)\n",
      " |      Returns the number of leaves of the decision tree.\n",
      " |  \n",
      " |  predict(self, X, check_input=True)\n",
      " |      Predict class or regression value for X.\n",
      " |      \n",
      " |      For a classification model, the predicted class for each sample in X is\n",
      " |      returned. For a regression model, the predicted value based on X is\n",
      " |      returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix of shape = [n_samples, n_features]\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : boolean, (default=True)\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array of shape = [n_samples] or [n_samples, n_outputs]\n",
      " |          The predicted classes, or the predict values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseDecisionTree:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Return the feature importances.\n",
      " |      \n",
      " |      The importance of a feature is computed as the (normalized) total\n",
      " |      reduction of the criterion brought by that feature.\n",
      " |      It is also known as the Gini importance.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : array, shape = [n_features]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the coefficient of determination R^2 of the prediction.\n",
      " |      \n",
      " |      The coefficient R^2 is defined as (1 - u/v), where u is the residual\n",
      " |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n",
      " |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always\n",
      " |      predicts the expected value of y, disregarding the input features,\n",
      " |      would get a R^2 score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a\n",
      " |          precomputed kernel matrix instead, shape = (n_samples,\n",
      " |          n_samples_fitted], where n_samples_fitted is the number of\n",
      " |          samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True values for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          R^2 of self.predict(X) wrt. y.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      The R2 score used when calling ``score`` on a regressor will use\n",
      " |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      " |      with `metrics.r2_score`. This will influence the ``score`` method of\n",
      " |      all the multioutput regressors (except for\n",
      " |      `multioutput.MultiOutputRegressor`). To specify the default value\n",
      " |      manually and avoid the warning, please either call `metrics.r2_score`\n",
      " |      directly or make a custom scorer with `metrics.make_scorer` (the\n",
      " |      built-in scorer ``'r2'`` uses ``multioutput='uniform_average'``).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(DecisionTreeRegressor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.score(X_train,Y_train) #training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8878863675631422"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.score(X_test,Y_test) #test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from time import time\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to perform grid search with cross validation and returns the accuracy values\n",
    "def GridSearch_BestParam(X, y, clf, param_grid,cv=10):\n",
    "    grid_search = GridSearchCV(clf,\n",
    "                              param_grid=param_grid,\n",
    "                              cv=cv)\n",
    "    start= time()\n",
    "    grid_search.fit(X,y)\n",
    "    top_params=grid_search.best_estimator_\n",
    "    return top_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"criterion\": [\"mae\",\"mse\",\"friedman_mse\"],\n",
    "             \"min_samples_split\": [20,23,25,28,30],\n",
    "             \"max_depth\": [10,13,15,18,20],\n",
    "             \"min_samples_leaf\":[1,2,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvDT = tree.DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor(criterion='mae', max_depth=13, max_features=None,\n",
      "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
      "                      presort=False, random_state=None, splitter='best')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vipin\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "top_para = GridSearch_BestParam(X_train,Y_train, cvDT, param_grid, cv=10)\n",
    "print (top_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mae', max_depth=13, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only for classifier\n",
    "#top_score = sorted(top_para,key=itemgetter(1), reverse=True)\n",
    "#top_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for classifier only\n",
    "#paramCV = top_score[0].parameters\n",
    "#paramCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'paramCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-f1dc6a1b77b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m best_model = tree.DecisionTreeRegressor(max_depth=paramCV['max_depth'], min_samples_split=paramCV['min_samples_split'],\n\u001b[0m\u001b[0;32m      2\u001b[0m                                     \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparamCV\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'min_samples_leaf'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                    criterion=paramCV['criterion'])\n\u001b[0;32m      4\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'paramCV' is not defined"
     ]
    }
   ],
   "source": [
    "best_model = tree.DecisionTreeRegressor(max_depth=paramCV['max_depth'], min_samples_split=paramCV['min_samples_split'],\n",
    "                                    min_samples_leaf=paramCV['min_samples_leaf'],\n",
    "                                   criterion=paramCV['criterion'])\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = top_para.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([33.2 , 23.9 ,  8.8 , 21.2 , 15.15, 23.9 , 20.35, 17.2 , 17.55,\n",
       "       27.25, 17.2 , 21.2 , 23.  , 18.2 , 17.55, 23.5 ,  8.8 , 19.  ,\n",
       "       20.2 ,  8.8 , 32.55, 20.6 , 20.2 , 14.4 , 23.9 , 20.6 , 20.2 ,\n",
       "       25.  , 27.1 , 17.2 , 20.35, 19.  , 18.2 , 11.95, 23.5 , 14.1 ,\n",
       "       20.  , 23.  ,  8.8 ,  8.8 ,  8.8 , 18.2 , 42.8 , 27.1 , 20.2 ,\n",
       "       27.25, 27.25, 50.  , 19.  , 23.5 , 20.2 , 33.2 , 28.7 , 25.  ,\n",
       "       50.  , 32.55,  8.8 , 33.2 , 28.7 , 21.2 , 32.55, 15.15, 20.35,\n",
       "       32.55,  8.8 , 20.6 , 33.2 , 20.  , 50.  , 42.8 , 15.  , 23.9 ,\n",
       "       17.2 , 17.2 , 25.  , 15.15, 42.8 , 22.45, 17.2 , 17.2 , 42.8 ,\n",
       "       50.  , 25.  , 17.2 , 20.6 , 17.2 , 23.9 , 32.55, 20.6 , 20.6 ,\n",
       "       19.  ,  7.55, 22.4 , 19.  , 13.8 , 42.8 , 19.  , 16.5 , 27.25,\n",
       "       27.25, 18.4 , 20.35])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YValid_Pred = best_model.predict(X_test) # use XTest, XValid to generate prediction\n",
    "YValid_Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8563706748738276"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.r2_score(Y_test,YValid_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9352115302800984"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8563706748738277"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06376841, 0.        , 0.02368541, 0.        , 0.02894883,\n",
       "       0.42664102, 0.02565919, 0.07110684, 0.002075  , 0.01751101,\n",
       "       0.02717749, 0.01994028, 0.29348651])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overfiting the model\n",
    "# drawback of using train/test model evaluation is incorrect\n",
    "# to control over fitting of the model, we are going to use CV\n",
    "# cross validation tunes the parameters, selects best model, does feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv',\n",
    "                  sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      "fixed acidity           1599 non-null float64\n",
      "volatile acidity        1599 non-null float64\n",
      "citric acid             1599 non-null float64\n",
      "residual sugar          1599 non-null float64\n",
      "chlorides               1599 non-null float64\n",
      "free sulfur dioxide     1599 non-null float64\n",
      "total sulfur dioxide    1599 non-null float64\n",
      "density                 1599 non-null float64\n",
      "pH                      1599 non-null float64\n",
      "sulphates               1599 non-null float64\n",
      "alcohol                 1599 non-null float64\n",
      "quality                 1599 non-null int64\n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3, 4, 5, 6, 7, 8}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(data.quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['quality'] = pd.Categorical(data.quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      "fixed acidity           1599 non-null float64\n",
      "volatile acidity        1599 non-null float64\n",
      "citric acid             1599 non-null float64\n",
      "residual sugar          1599 non-null float64\n",
      "chlorides               1599 non-null float64\n",
      "free sulfur dioxide     1599 non-null float64\n",
      "total sulfur dioxide    1599 non-null float64\n",
      "density                 1599 non-null float64\n",
      "pH                      1599 non-null float64\n",
      "sulphates               1599 non-null float64\n",
      "alcohol                 1599 non-null float64\n",
      "quality                 1599 non-null category\n",
      "dtypes: category(1), float64(11)\n",
      "memory usage: 139.3 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
       "       'pH', 'sulphates', 'alcohol', 'quality'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "       'pH', 'sulphates', 'alcohol']]\n",
    "target = data['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(data,target,test_size=0.10,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1439, 12), (160, 12), (1439,), (160,))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape,y_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt2 = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt2.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt2.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = dt2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  0,  0,  0,  0],\n",
       "       [ 0, 71,  0,  0,  0],\n",
       "       [ 0,  0, 61,  0,  0],\n",
       "       [ 0,  0,  0, 23,  0],\n",
       "       [ 0,  0,  0,  0,  2]], dtype=int64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_data = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\",sep=',',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| This data was extracted from the census bureau database found at\n",
    "| http://www.census.gov/ftp/pub/DES/www/welcome.html\n",
    "| Donor: Ronny Kohavi and Barry Becker,\n",
    "|        Data Mining and Visualization\n",
    "|        Silicon Graphics.\n",
    "|        e-mail: ronnyk@sgi.com for questions.\n",
    "| Split into train-test using MLC++ GenCVFiles (2/3, 1/3 random).\n",
    "| 48842 instances, mix of continuous and discrete    (train=32561, test=16281)\n",
    "| 45222 if instances with unknown values are removed (train=30162, test=15060)\n",
    "| Duplicate or conflicting instances : 6\n",
    "| Class probabilities for adult.all file\n",
    "| Probability for the label '>50K'  : 23.93% / 24.78% (without unknowns)\n",
    "| Probability for the label '<=50K' : 76.07% / 75.22% (without unknowns)\n",
    "|\n",
    "| Extraction was done by Barry Becker from the 1994 Census database.  A set of\n",
    "|   reasonably clean records was extracted using the following conditions:\n",
    "|   ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\n",
    "|\n",
    "| Prediction task is to determine whether a person makes over 50K\n",
    "| a year.\n",
    "|\n",
    "| First cited in:\n",
    "| @inproceedings{kohavi-nbtree,\n",
    "|    author={Ron Kohavi},\n",
    "|    title={Scaling Up the Accuracy of Naive-Bayes Classifiers: a\n",
    "|           Decision-Tree Hybrid},\n",
    "|    booktitle={Proceedings of the Second International Conference on\n",
    "|               Knowledge Discovery and Data Mining},\n",
    "|    year = 1996,\n",
    "|    pages={to appear}}\n",
    "|\n",
    "| Error Accuracy reported as follows, after removal of unknowns from\n",
    "|    train/test sets):\n",
    "|    C4.5       : 84.46+-0.30\n",
    "|    Naive-Bayes: 83.88+-0.30\n",
    "|    NBTree     : 85.90+-0.28\n",
    "|\n",
    "|\n",
    "| Following algorithms were later run with the following error rates,\n",
    "|    all after removal of unknowns and using the original train/test split.\n",
    "|    All these numbers are straight runs using MLC++ with default values.\n",
    "|\n",
    "|    Algorithm               Error\n",
    "| -- ----------------        -----\n",
    "| 1  C4.5                    15.54\n",
    "| 2  C4.5-auto               14.46\n",
    "| 3  C4.5 rules              14.94\n",
    "| 4  Voted ID3 (0.6)         15.64\n",
    "| 5  Voted ID3 (0.8)         16.47\n",
    "| 6  T2                      16.84\n",
    "| 7  1R                      19.54\n",
    "| 8  NBTree                  14.10\n",
    "| 9  CN2                     16.00\n",
    "| 10 HOODG                   14.82\n",
    "| 11 FSS Naive Bayes         14.05\n",
    "| 12 IDTM (Decision table)   14.46\n",
    "| 13 Naive-Bayes             16.12\n",
    "| 14 Nearest-neighbor (1)    21.42\n",
    "| 15 Nearest-neighbor (3)    20.35\n",
    "| 16 OC1                     15.04\n",
    "| 17 Pebls                   Crashed.  Unknown why (bounds WERE increased)\n",
    "|\n",
    "| Conversion of original data as follows:\n",
    "| 1. Discretized agrossincome into two ranges with threshold 50,000.\n",
    "| 2. Convert U.S. to US to avoid periods.\n",
    "| 3. Convert Unknown to \"?\"\n",
    "| 4. Run MLC++ GenCVFiles to generate data,test.\n",
    "|\n",
    "| Description of fnlwgt (final weight)\n",
    "|\n",
    "| The weights on the CPS files are controlled to independent estimates of the\n",
    "| civilian noninstitutional population of the US.  These are prepared monthly\n",
    "| for us by Population Division here at the Census Bureau.  We use 3 sets of\n",
    "| controls.\n",
    "|  These are:\n",
    "|          1.  A single cell estimate of the population 16+ for each state.\n",
    "|          2.  Controls for Hispanic Origin by age and sex.\n",
    "|          3.  Controls by Race, age and sex.\n",
    "|\n",
    "| We use all three sets of controls in our weighting program and \"rake\" through\n",
    "| them 6 times so that by the end we come back to all the controls we used.\n",
    "|\n",
    "| The term estimate refers to population totals derived from CPS by creating\n",
    "| \"weighted tallies\" of any specified socio-economic characteristics of the\n",
    "| population.\n",
    "|\n",
    "| People with similar demographic characteristics should have\n",
    "| similar weights.  There is one important caveat to remember\n",
    "| about this statement.  That is that since the CPS sample is\n",
    "| actually a collection of 51 state samples, each with its own\n",
    "| probability of selection, the statement only applies within\n",
    "| state.\n",
    "\n",
    "\n",
    ">50K, <=50K.\n",
    "\n",
    "age: continuous.\n",
    "workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "fnlwgt: continuous.\n",
    "education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "education-num: continuous.\n",
    "marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "sex: Female, Male.\n",
    "capital-gain: continuous.\n",
    "capital-loss: continuous.\n",
    "hours-per-week: continuous.\n",
    "native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                  1       2           3   4                    5   \\\n",
       "0  39          State-gov   77516   Bachelors  13        Never-married   \n",
       "1  50   Self-emp-not-inc   83311   Bachelors  13   Married-civ-spouse   \n",
       "2  38            Private  215646     HS-grad   9             Divorced   \n",
       "3  53            Private  234721        11th   7   Married-civ-spouse   \n",
       "4  28            Private  338409   Bachelors  13   Married-civ-spouse   \n",
       "\n",
       "                   6               7       8        9     10  11  12  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male  2174   0  40   \n",
       "1     Exec-managerial         Husband   White     Male     0   0  13   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male     0   0  40   \n",
       "3   Handlers-cleaners         Husband   Black     Male     0   0  40   \n",
       "4      Prof-specialty            Wife   Black   Female     0   0  40   \n",
       "\n",
       "               13      14  \n",
       "0   United-States   <=50K  \n",
       "1   United-States   <=50K  \n",
       "2   United-States   <=50K  \n",
       "3   United-States   <=50K  \n",
       "4            Cuba   <=50K  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_data.columns = ['age','workclass','fnlwgt','education','education_num','marital_status','occupation',\n",
    "                  'relationship','race','sex','capital_gain','capital_loss','hours_per_week','native_country','income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education_num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital_status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week  native_country  income  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      "age               32561 non-null int64\n",
      "workclass         32561 non-null object\n",
      "fnlwgt            32561 non-null int64\n",
      "education         32561 non-null object\n",
      "education_num     32561 non-null int64\n",
      "marital_status    32561 non-null object\n",
      "occupation        32561 non-null object\n",
      "relationship      32561 non-null object\n",
      "race              32561 non-null object\n",
      "sex               32561 non-null object\n",
      "capital_gain      32561 non-null int64\n",
      "capital_loss      32561 non-null int64\n",
      "hours_per_week    32561 non-null int64\n",
      "native_country    32561 non-null object\n",
      "income            32561 non-null object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "ad_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ad_data[['age','fnlwgt','education_num',\n",
    "                  'capital_gain','capital_loss','hours_per_week']]\n",
    "target = ad_data.income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "male = pd.get_dummies(ad_data.sex,prefix='sex',drop_first=True)\n",
    "workclass = pd.get_dummies(ad_data.workclass,prefix='workclass',drop_first=True)\n",
    "education = pd.get_dummies(ad_data.education,prefix='education',drop_first=True)\n",
    "marital_status = pd.get_dummies(ad_data.marital_status,prefix='marital_status',drop_first=True)\n",
    "occupation = pd.get_dummies(ad_data.occupation,prefix='occupation',drop_first=True)\n",
    "relationship = pd.get_dummies(ad_data.relationship,prefix='relationship',drop_first=True)\n",
    "race = pd.get_dummies(ad_data.race,prefix='race',drop_first=True)\n",
    "\n",
    "cdata = pd.concat([male,workclass,education,marital_status,occupation,relationship,race,features],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex_ Male</th>\n",
       "      <th>workclass_ Federal-gov</th>\n",
       "      <th>workclass_ Local-gov</th>\n",
       "      <th>workclass_ Never-worked</th>\n",
       "      <th>workclass_ Private</th>\n",
       "      <th>workclass_ Self-emp-inc</th>\n",
       "      <th>workclass_ Self-emp-not-inc</th>\n",
       "      <th>workclass_ State-gov</th>\n",
       "      <th>workclass_ Without-pay</th>\n",
       "      <th>education_ 11th</th>\n",
       "      <th>...</th>\n",
       "      <th>race_ Asian-Pac-Islander</th>\n",
       "      <th>race_ Black</th>\n",
       "      <th>race_ Other</th>\n",
       "      <th>race_ White</th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex_ Male  workclass_ Federal-gov  workclass_ Local-gov  \\\n",
       "0          1                       0                     0   \n",
       "1          1                       0                     0   \n",
       "2          1                       0                     0   \n",
       "3          1                       0                     0   \n",
       "4          0                       0                     0   \n",
       "\n",
       "   workclass_ Never-worked  workclass_ Private  workclass_ Self-emp-inc  \\\n",
       "0                        0                   0                        0   \n",
       "1                        0                   0                        0   \n",
       "2                        0                   1                        0   \n",
       "3                        0                   1                        0   \n",
       "4                        0                   1                        0   \n",
       "\n",
       "   workclass_ Self-emp-not-inc  workclass_ State-gov  workclass_ Without-pay  \\\n",
       "0                            0                     1                       0   \n",
       "1                            1                     0                       0   \n",
       "2                            0                     0                       0   \n",
       "3                            0                     0                       0   \n",
       "4                            0                     0                       0   \n",
       "\n",
       "   education_ 11th       ...        race_ Asian-Pac-Islander  race_ Black  \\\n",
       "0                0       ...                               0            0   \n",
       "1                0       ...                               0            0   \n",
       "2                0       ...                               0            0   \n",
       "3                1       ...                               0            1   \n",
       "4                0       ...                               0            1   \n",
       "\n",
       "   race_ Other  race_ White  age  fnlwgt  education_num  capital_gain  \\\n",
       "0            0            1   39   77516             13          2174   \n",
       "1            0            1   50   83311             13             0   \n",
       "2            0            1   38  215646              9             0   \n",
       "3            0            0   53  234721              7             0   \n",
       "4            0            0   28  338409             13             0   \n",
       "\n",
       "   capital_loss  hours_per_week  \n",
       "0             0              40  \n",
       "1             0              13  \n",
       "2             0              40  \n",
       "3             0              40  \n",
       "4             0              40  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 59 columns):\n",
      "sex_ Male                                32561 non-null uint8\n",
      "workclass_ Federal-gov                   32561 non-null uint8\n",
      "workclass_ Local-gov                     32561 non-null uint8\n",
      "workclass_ Never-worked                  32561 non-null uint8\n",
      "workclass_ Private                       32561 non-null uint8\n",
      "workclass_ Self-emp-inc                  32561 non-null uint8\n",
      "workclass_ Self-emp-not-inc              32561 non-null uint8\n",
      "workclass_ State-gov                     32561 non-null uint8\n",
      "workclass_ Without-pay                   32561 non-null uint8\n",
      "education_ 11th                          32561 non-null uint8\n",
      "education_ 12th                          32561 non-null uint8\n",
      "education_ 1st-4th                       32561 non-null uint8\n",
      "education_ 5th-6th                       32561 non-null uint8\n",
      "education_ 7th-8th                       32561 non-null uint8\n",
      "education_ 9th                           32561 non-null uint8\n",
      "education_ Assoc-acdm                    32561 non-null uint8\n",
      "education_ Assoc-voc                     32561 non-null uint8\n",
      "education_ Bachelors                     32561 non-null uint8\n",
      "education_ Doctorate                     32561 non-null uint8\n",
      "education_ HS-grad                       32561 non-null uint8\n",
      "education_ Masters                       32561 non-null uint8\n",
      "education_ Preschool                     32561 non-null uint8\n",
      "education_ Prof-school                   32561 non-null uint8\n",
      "education_ Some-college                  32561 non-null uint8\n",
      "marital_status_ Married-AF-spouse        32561 non-null uint8\n",
      "marital_status_ Married-civ-spouse       32561 non-null uint8\n",
      "marital_status_ Married-spouse-absent    32561 non-null uint8\n",
      "marital_status_ Never-married            32561 non-null uint8\n",
      "marital_status_ Separated                32561 non-null uint8\n",
      "marital_status_ Widowed                  32561 non-null uint8\n",
      "occupation_ Adm-clerical                 32561 non-null uint8\n",
      "occupation_ Armed-Forces                 32561 non-null uint8\n",
      "occupation_ Craft-repair                 32561 non-null uint8\n",
      "occupation_ Exec-managerial              32561 non-null uint8\n",
      "occupation_ Farming-fishing              32561 non-null uint8\n",
      "occupation_ Handlers-cleaners            32561 non-null uint8\n",
      "occupation_ Machine-op-inspct            32561 non-null uint8\n",
      "occupation_ Other-service                32561 non-null uint8\n",
      "occupation_ Priv-house-serv              32561 non-null uint8\n",
      "occupation_ Prof-specialty               32561 non-null uint8\n",
      "occupation_ Protective-serv              32561 non-null uint8\n",
      "occupation_ Sales                        32561 non-null uint8\n",
      "occupation_ Tech-support                 32561 non-null uint8\n",
      "occupation_ Transport-moving             32561 non-null uint8\n",
      "relationship_ Not-in-family              32561 non-null uint8\n",
      "relationship_ Other-relative             32561 non-null uint8\n",
      "relationship_ Own-child                  32561 non-null uint8\n",
      "relationship_ Unmarried                  32561 non-null uint8\n",
      "relationship_ Wife                       32561 non-null uint8\n",
      "race_ Asian-Pac-Islander                 32561 non-null uint8\n",
      "race_ Black                              32561 non-null uint8\n",
      "race_ Other                              32561 non-null uint8\n",
      "race_ White                              32561 non-null uint8\n",
      "age                                      32561 non-null int64\n",
      "fnlwgt                                   32561 non-null int64\n",
      "education_num                            32561 non-null int64\n",
      "capital_gain                             32561 non-null int64\n",
      "capital_loss                             32561 non-null int64\n",
      "hours_per_week                           32561 non-null int64\n",
      "dtypes: int64(6), uint8(53)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "cdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ad_data['marital_status'] = pd.Categorical(ad_data.marital_status)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(cdata,target,test_size=0.20,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26048, 59), (6513, 59), (26048,), (6513,))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt3 = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = dt3.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999616093366094"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8131429448794718"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([25, 53, 54, 55, 56, 58], dtype=int64),)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(model4.feature_importances_>0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = pd.Series(cdata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = pd.Series(np.round(model4.feature_importances_,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = pd.concat([colnames,imp],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp.columns = ['var','score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>marital_status_ Married-civ-spouse</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>fnlwgt</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>education_num</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>age</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>capital_gain</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>hours_per_week</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>capital_loss</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>relationship_ Wife</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>occupation_ Tech-support</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>occupation_ Sales</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   var  score\n",
       "25  marital_status_ Married-civ-spouse   0.20\n",
       "54                              fnlwgt   0.18\n",
       "55                       education_num   0.12\n",
       "53                                 age   0.12\n",
       "56                        capital_gain   0.11\n",
       "58                      hours_per_week   0.07\n",
       "57                        capital_loss   0.04\n",
       "48                  relationship_ Wife   0.01\n",
       "42            occupation_ Tech-support   0.01\n",
       "41                   occupation_ Sales   0.01"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp.sort_values(by='score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_features = feat_imp.sort_values(by='score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in e:\\new folder\\lib\\site-packages\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\new folder\\lib\\site-packages (from matplotlib)\n",
      "Requirement already satisfied: numpy>=1.11 in e:\\new folder\\lib\\site-packages (from matplotlib)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\new folder\\lib\\site-packages (from matplotlib)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in e:\\new folder\\lib\\site-packages (from matplotlib)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in e:\\new folder\\lib\\site-packages (from matplotlib)\n",
      "Requirement already satisfied: setuptools in e:\\new folder\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib)\n",
      "Requirement already satisfied: six in e:\\new folder\\lib\\site-packages (from cycler>=0.10->matplotlib)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999616093366094"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8131429448794718"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps in K-fold cross validation\n",
    "#1- split the dataset into K- equal parts\n",
    "#2- use fold 1 as the testing set and the union of other folds as training set\n",
    "#3- calculate testing accuracy\n",
    "#4- repeat step 2 and 3\n",
    "#5- use the average testing accuracy as the estimate of the out of the sample accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=10, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8127687241445762, 0.8141507187655795, 0.812615151172358, 0.8146883236565682, 0.8129606627242308, 0.81257679293442, 0.8129990283316673, 0.8140357472247391, 0.8134597398788234, 0.8146882057445974, 0.8134214479663686, 0.8129990872876526, 0.8141891801764922, 0.8128839388788561]\n"
     ]
    }
   ],
   "source": [
    "k_range = list(range(1,15))\n",
    "k_scores = []\n",
    "for k in k_range:\n",
    "    dt3 = tree.DecisionTreeClassifier()\n",
    "    scores = cross_val_score(dt3,X_train,y_train,cv=5,scoring='accuracy')\n",
    "    k_scores.append(scores.mean())\n",
    "print(k_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8134597677776378"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0007239199366869272"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15e8e7acf28>]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "plt.plot(k_range,k_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x15e8ea12780>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(y=k_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.sqrt(59),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "YPred = model4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4344  576]\n",
      " [ 641  952]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.87      0.88      0.88      4920\n",
      "        >50K       0.62      0.60      0.61      1593\n",
      "\n",
      "    accuracy                           0.81      6513\n",
      "   macro avg       0.75      0.74      0.74      6513\n",
      "weighted avg       0.81      0.81      0.81      6513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "print(confusion_matrix(YPred,y_test))\n",
    "print(classification_report(YPred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# what is the problem with model4:\n",
    "# biased model as it looks at 6 important features and because it is a single decision tree\n",
    "# other least important features are not getting a place in the tree construction process\n",
    "\n",
    "# to remove this bias from the model we can procees with a random forest classifier\n",
    "# because the RF model strikes a right balance between the bias and variance\n",
    "\n",
    "# this is done by including the random features and many trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble as ske"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=6, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################Random Forest Model########################\n",
    "\n",
    "rf1 = ske.RandomForestClassifier(n_estimators=500, max_features=6).fit(X_train,y_train)\n",
    "rf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(ske.RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "YTestProb = rf1.predict_proba(X_test)\n",
    "YPred = rf1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4616  608]\n",
      " [ 369  920]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.93      0.88      0.90      5224\n",
      "        >50K       0.60      0.71      0.65      1289\n",
      "\n",
      "    accuracy                           0.85      6513\n",
      "   macro avg       0.76      0.80      0.78      6513\n",
      "weighted avg       0.86      0.85      0.85      6513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "print(confusion_matrix(YPred,y_test))\n",
    "print(classification_report(YPred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "YTestProb = rf1.predict_proba(X_test)\n",
    "YPred = rf1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4616  608]\n",
      " [ 369  920]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.93      0.88      0.90      5224\n",
      "        >50K       0.60      0.71      0.65      1289\n",
      "\n",
      "    accuracy                           0.85      6513\n",
      "   macro avg       0.76      0.80      0.78      6513\n",
      "weighted avg       0.86      0.85      0.85      6513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "print(confusion_matrix(YPred,y_test))\n",
    "print(classification_report(YPred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1368x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(19,10))\n",
    "pd.DataFrame(rf1.feature_importances_).plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'criterion':['gini','entropy'],\n",
    "             'max_depth': [2, 5, 7,10],\n",
    "             'n_estimators':[100,200,300,500],\n",
    "             'max_features': [4,6,8,10]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvRF = ske.RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvRF_Param = GridSearch_BestParam(X_train,y_train,cvRF, param_grid,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=10, max_features=10, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvRF_Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DecisionTreeClassifier' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-148-a0f048a52cf3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparamCV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcvRF_Param\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'DecisionTreeClassifier' object does not support indexing"
     ]
    }
   ],
   "source": [
    "paramCV = sorted(cvRF_Param,key=itemgetter(0), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'paramCV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-145-7a86502db063>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparamCV\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparamCV\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'paramCV' is not defined"
     ]
    }
   ],
   "source": [
    "paramCV = paramCV[0].parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paramCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=10, max_features=10, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvRF = ske.RandomForestClassifier(n_estimators=200,\n",
    "                                  criterion=\"gini\",\n",
    "                                  max_depth=10,\n",
    "                                  max_features=10\n",
    "                                )\n",
    "\n",
    "cvRF.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cvRF.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4732  253]\n",
      " [ 693  835]]\n"
     ]
    }
   ],
   "source": [
    "YValidRF = cvRF.predict(X_test)\n",
    "\n",
    "print (confusion_matrix(y_test,YValidRF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.870546683046683"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvRF.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8547520343927529"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvRF.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.50777213e-02, 2.29661643e-03, 1.27572576e-03, 0.00000000e+00,\n",
       "       2.72981467e-03, 2.41672318e-03, 4.28674392e-03, 1.13045460e-03,\n",
       "       1.59193038e-06, 1.54149529e-03, 1.20675442e-04, 4.96372305e-05,\n",
       "       1.49189873e-04, 1.51231916e-03, 6.57272512e-04, 6.28767512e-04,\n",
       "       9.49615532e-04, 1.98530255e-02, 3.54945585e-03, 8.00446454e-03,\n",
       "       8.50369920e-03, 3.51437789e-06, 7.99964501e-03, 3.34473780e-03,\n",
       "       5.16585902e-04, 2.08455576e-01, 5.09045961e-04, 7.04485035e-02,\n",
       "       1.09701346e-03, 1.15846580e-03, 1.34559809e-03, 3.10948855e-06,\n",
       "       1.32099237e-03, 3.30279406e-02, 2.65463460e-03, 9.12308673e-04,\n",
       "       1.01746545e-03, 5.00861977e-03, 2.79802686e-05, 1.98744853e-02,\n",
       "       7.45975634e-04, 2.02938325e-03, 2.73441530e-03, 7.47361133e-04,\n",
       "       2.83218677e-02, 1.11545307e-03, 1.79467362e-02, 1.29468451e-02,\n",
       "       8.66545566e-03, 1.16138460e-03, 1.25966591e-03, 2.22077682e-04,\n",
       "       1.81728577e-03, 6.18816903e-02, 1.50223656e-02, 1.34705240e-01,\n",
       "       1.82211009e-01, 3.95895565e-02, 4.34150006e-02])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvRF.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_RF = pd.Series(np.round(cvRF.feature_importances_,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp['score_rf'] = imp_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>score</th>\n",
       "      <th>score_rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>marital_status_ Married-civ-spouse</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>capital_gain</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>education_num</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>marital_status_ Never-married</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>age</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>hours_per_week</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>capital_loss</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>relationship_ Not-in-family</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>occupation_ Exec-managerial</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sex_ Male</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   var  score  score_rf\n",
       "25  marital_status_ Married-civ-spouse   0.20      0.21\n",
       "56                        capital_gain   0.11      0.18\n",
       "55                       education_num   0.12      0.13\n",
       "27       marital_status_ Never-married   0.00      0.07\n",
       "53                                 age   0.12      0.06\n",
       "58                      hours_per_week   0.07      0.04\n",
       "57                        capital_loss   0.04      0.04\n",
       "44         relationship_ Not-in-family   0.00      0.03\n",
       "33         occupation_ Exec-managerial   0.01      0.03\n",
       "0                            sex_ Male   0.01      0.03"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp.sort_values(by='score_rf', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>score</th>\n",
       "      <th>score_rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>marital_status_ Married-spouse-absent</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>workclass_ Without-pay</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>marital_status_ Separated</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>workclass_ Federal-gov</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>occupation_ Adm-clerical</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>occupation_ Armed-Forces</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>occupation_ Craft-repair</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>workclass_ State-gov</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>education_ 1st-4th</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>marital_status_ Widowed</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      var  score  score_rf\n",
       "26  marital_status_ Married-spouse-absent   0.00       0.0\n",
       "8                  workclass_ Without-pay   0.00       0.0\n",
       "28              marital_status_ Separated   0.00       0.0\n",
       "1                  workclass_ Federal-gov   0.00       0.0\n",
       "30               occupation_ Adm-clerical   0.01       0.0\n",
       "31               occupation_ Armed-Forces   0.00       0.0\n",
       "32               occupation_ Craft-repair   0.01       0.0\n",
       "7                    workclass_ State-gov   0.00       0.0\n",
       "11                     education_ 1st-4th   0.00       0.0\n",
       "29                marital_status_ Widowed   0.00       0.0"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp.sort_values(by='score_rf', ascending=False).tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(cvRF.feature_importances_<0.01)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = feat_imp[feat_imp.score_rf<0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list.columns = ['variables', 'score', 'score_rf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 3)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'education_ 11th',\n",
       " 'education_ 12th',\n",
       " 'education_ 1st-4th',\n",
       " 'education_ 5th-6th',\n",
       " 'education_ 7th-8th',\n",
       " 'education_ 9th',\n",
       " 'education_ Assoc-acdm',\n",
       " 'education_ Assoc-voc',\n",
       " 'education_ Doctorate',\n",
       " 'education_ Preschool',\n",
       " 'education_ Some-college',\n",
       " 'marital_status_ Married-AF-spouse',\n",
       " 'marital_status_ Married-spouse-absent',\n",
       " 'marital_status_ Separated',\n",
       " 'marital_status_ Widowed',\n",
       " 'occupation_ Adm-clerical',\n",
       " 'occupation_ Armed-Forces',\n",
       " 'occupation_ Craft-repair',\n",
       " 'occupation_ Farming-fishing',\n",
       " 'occupation_ Handlers-cleaners',\n",
       " 'occupation_ Machine-op-inspct',\n",
       " 'occupation_ Priv-house-serv',\n",
       " 'occupation_ Protective-serv',\n",
       " 'occupation_ Sales',\n",
       " 'occupation_ Tech-support',\n",
       " 'occupation_ Transport-moving',\n",
       " 'race_ Asian-Pac-Islander',\n",
       " 'race_ Black',\n",
       " 'race_ Other',\n",
       " 'race_ White',\n",
       " 'relationship_ Other-relative',\n",
       " 'workclass_ Federal-gov',\n",
       " 'workclass_ Local-gov',\n",
       " 'workclass_ Never-worked',\n",
       " 'workclass_ Private',\n",
       " 'workclass_ Self-emp-inc',\n",
       " 'workclass_ Self-emp-not-inc',\n",
       " 'workclass_ State-gov',\n",
       " 'workclass_ Without-pay'}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(var_list.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdata_new = cdata[['education_ 11th',\n",
    " 'education_ 12th',\n",
    " 'education_ 1st-4th',\n",
    " 'education_ 5th-6th',\n",
    " 'education_ 7th-8th',\n",
    " 'education_ 9th',\n",
    " 'education_ Assoc-acdm',\n",
    " 'education_ Assoc-voc',\n",
    " 'education_ Doctorate',\n",
    " 'education_ Preschool',\n",
    " 'education_ Prof-school',\n",
    " 'education_ Some-college',\n",
    " 'fnlwgt',\n",
    " 'marital_status_ Married-AF-spouse',\n",
    " 'marital_status_ Married-spouse-absent',\n",
    " 'marital_status_ Separated',\n",
    " 'marital_status_ Widowed',\n",
    " 'occupation_ Adm-clerical',\n",
    " 'occupation_ Armed-Forces',\n",
    " 'occupation_ Craft-repair',\n",
    " 'occupation_ Farming-fishing',\n",
    " 'occupation_ Handlers-cleaners',\n",
    " 'occupation_ Machine-op-inspct',\n",
    " 'occupation_ Priv-house-serv',\n",
    " 'occupation_ Protective-serv',\n",
    " 'occupation_ Sales',\n",
    " 'occupation_ Tech-support',\n",
    " 'occupation_ Transport-moving',\n",
    " 'race_ Asian-Pac-Islander',\n",
    " 'race_ Black',\n",
    " 'race_ Other',\n",
    " 'race_ White',\n",
    " 'relationship_ Other-relative',\n",
    " 'workclass_ Federal-gov',\n",
    " 'workclass_ Local-gov',\n",
    " 'workclass_ Never-worked',\n",
    " 'workclass_ Private',\n",
    " 'workclass_ Self-emp-inc',\n",
    " 'workclass_ Self-emp-not-inc',\n",
    " 'workclass_ State-gov',\n",
    " 'workclass_ Without-pay']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['education_ 11th', 'education_ 12th', 'education_ 1st-4th',\n",
       "       'education_ 5th-6th', 'education_ 7th-8th', 'education_ 9th',\n",
       "       'education_ Assoc-acdm', 'education_ Assoc-voc', 'education_ Doctorate',\n",
       "       'education_ Preschool', 'education_ Prof-school',\n",
       "       'education_ Some-college', 'fnlwgt',\n",
       "       'marital_status_ Married-AF-spouse',\n",
       "       'marital_status_ Married-spouse-absent', 'marital_status_ Separated',\n",
       "       'marital_status_ Widowed', 'occupation_ Adm-clerical',\n",
       "       'occupation_ Armed-Forces', 'occupation_ Craft-repair',\n",
       "       'occupation_ Farming-fishing', 'occupation_ Handlers-cleaners',\n",
       "       'occupation_ Machine-op-inspct', 'occupation_ Priv-house-serv',\n",
       "       'occupation_ Protective-serv', 'occupation_ Sales',\n",
       "       'occupation_ Tech-support', 'occupation_ Transport-moving',\n",
       "       'race_ Asian-Pac-Islander', 'race_ Black', 'race_ Other', 'race_ White',\n",
       "       'relationship_ Other-relative', 'workclass_ Federal-gov',\n",
       "       'workclass_ Local-gov', 'workclass_ Never-worked', 'workclass_ Private',\n",
       "       'workclass_ Self-emp-inc', 'workclass_ Self-emp-not-inc',\n",
       "       'workclass_ State-gov', 'workclass_ Without-pay'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdata_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1,y_test1 = train_test_split(cdata_new,target,test_size=0.20,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((26048, 41), (6513, 41), (26048,), (6513,))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.shape, X_test1.shape, y_train1.shape,y_test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt3.fit(X_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.992129914004914"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt3.score(X_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6953784738215876"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt3.score(X_test1,y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=10, max_features=10, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvRF.fit(X_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7805205773955773"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvRF.score(X_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7801320436050975"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvRF.score(X_test1,y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_RF_reducedset = pd.Series(np.round(cvRF.feature_importances_,2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp['score_rf_reducedset'] = imp_RF_reducedset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>score</th>\n",
       "      <th>score_rf</th>\n",
       "      <th>score_rf_reducedset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>education_ 12th</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>workclass_ Without-pay</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>occupation_ Other-service</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>education_ 5th-6th</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>education_ Bachelors</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sex_ Male</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>education_ Preschool</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>occupation_ Craft-repair</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>occupation_ Armed-Forces</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>marital_status_ Widowed</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          var  score  score_rf  score_rf_reducedset\n",
       "10            education_ 12th   0.00      0.00                 0.19\n",
       "8      workclass_ Without-pay   0.00      0.00                 0.13\n",
       "37  occupation_ Other-service   0.00      0.01                 0.12\n",
       "12         education_ 5th-6th   0.00      0.00                 0.10\n",
       "17       education_ Bachelors   0.00      0.02                 0.06\n",
       "0                   sex_ Male   0.01      0.03                 0.05\n",
       "21       education_ Preschool   0.00      0.00                 0.05\n",
       "32   occupation_ Craft-repair   0.01      0.00                 0.03\n",
       "31   occupation_ Armed-Forces   0.00      0.00                 0.03\n",
       "29    marital_status_ Widowed   0.00      0.00                 0.03"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp.sort_values(by='score_rf_reducedset', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Gradient Boosting Model\n",
    "# 2. Xtreme Gradient Boosting\n",
    "# 3. Stochastic Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "bagging = BaggingClassifier(KNeighborsClassifier(),max_samples=0.5, max_features=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=KNeighborsClassifier(algorithm='auto',\n",
       "                                                      leaf_size=30,\n",
       "                                                      metric='minkowski',\n",
       "                                                      metric_params=None,\n",
       "                                                      n_jobs=None,\n",
       "                                                      n_neighbors=5, p=2,\n",
       "                                                      weights='uniform'),\n",
       "                  bootstrap=True, bootstrap_features=False, max_features=0.5,\n",
       "                  max_samples=0.5, n_estimators=10, n_jobs=None,\n",
       "                  oob_score=False, random_state=None, verbose=0,\n",
       "                  warm_start=False)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8709689803439803"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85014586212191"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagging.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, IsolationForest, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "bagging = BaggingClassifier(KNeighborsClassifier(),max_samples=0.5, max_features=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = ExtraTreesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = IsolationForest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf = VotingClassifier(estimators=[('dt', model4), ('rf', model6), ('dt1', model5)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vipin\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                     max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "                     oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vipin\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\iforest.py:237: FutureWarning: default contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n",
      "  FutureWarning)\n",
      "C:\\Users\\vipin\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IsolationForest(behaviour='old', bootstrap=False, contamination='legacy',\n",
       "                max_features=1.0, max_samples='auto', n_estimators=100,\n",
       "                n_jobs=None, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vipin\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\iforest.py:237: FutureWarning: default contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n",
      "  FutureWarning)\n",
      "C:\\Users\\vipin\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('dt',\n",
       "                              DecisionTreeClassifier(class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=None,\n",
       "                                                     max_features=None,\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     presort=False,\n",
       "                                                     random_state=None,\n",
       "                                                     splitter='best')),\n",
       "                             ('rf',\n",
       "                              IsolationForest(behaviour='old...\n",
       "                                                   class_weight=None,\n",
       "                                                   criterion='gini',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators=10, n_jobs=None,\n",
       "                                                   oob_score=False,\n",
       "                                                   random_state=None, verbose=0,\n",
       "                                                   warm_start=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999616093366094"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8304928604329802"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.36345241, -0.41494908, -0.49294052, ..., -0.37144294,\n",
       "       -0.4159455 , -0.35072033])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6.score_samples(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8657095334407561"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "scores.mean()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8530630601954842"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_test = cross_val_score(clf, X_test, y_test, cv=5)\n",
    "scores_test.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8660934327085595"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "scores.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8562875698641796"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(clf, X_test, y_test, cv=5)\n",
    "scores.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Xtreme Gradient Boosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stacking models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='auto',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on GradientBoostingClassifier in module sklearn.ensemble.gradient_boosting object:\n",
      "\n",
      "class GradientBoostingClassifier(BaseGradientBoosting, sklearn.base.ClassifierMixin)\n",
      " |  Gradient Boosting for classification.\n",
      " |  \n",
      " |  GB builds an additive model in a\n",
      " |  forward stage-wise fashion; it allows for the optimization of\n",
      " |  arbitrary differentiable loss functions. In each stage ``n_classes_``\n",
      " |  regression trees are fit on the negative gradient of the\n",
      " |  binomial or multinomial deviance loss function. Binary classification\n",
      " |  is a special case where only a single regression tree is induced.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <gradient_boosting>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  loss : {'deviance', 'exponential'}, optional (default='deviance')\n",
      " |      loss function to be optimized. 'deviance' refers to\n",
      " |      deviance (= logistic regression) for classification\n",
      " |      with probabilistic outputs. For loss 'exponential' gradient\n",
      " |      boosting recovers the AdaBoost algorithm.\n",
      " |  \n",
      " |  learning_rate : float, optional (default=0.1)\n",
      " |      learning rate shrinks the contribution of each tree by `learning_rate`.\n",
      " |      There is a trade-off between learning_rate and n_estimators.\n",
      " |  \n",
      " |  n_estimators : int (default=100)\n",
      " |      The number of boosting stages to perform. Gradient boosting\n",
      " |      is fairly robust to over-fitting so a large number usually\n",
      " |      results in better performance.\n",
      " |  \n",
      " |  subsample : float, optional (default=1.0)\n",
      " |      The fraction of samples to be used for fitting the individual base\n",
      " |      learners. If smaller than 1.0 this results in Stochastic Gradient\n",
      " |      Boosting. `subsample` interacts with the parameter `n_estimators`.\n",
      " |      Choosing `subsample < 1.0` leads to a reduction of variance\n",
      " |      and an increase in bias.\n",
      " |  \n",
      " |  criterion : string, optional (default=\"friedman_mse\")\n",
      " |      The function to measure the quality of a split. Supported criteria\n",
      " |      are \"friedman_mse\" for the mean squared error with improvement\n",
      " |      score by Friedman, \"mse\" for mean squared error, and \"mae\" for\n",
      " |      the mean absolute error. The default value of \"friedman_mse\" is\n",
      " |      generally the best as it can provide a better approximation in\n",
      " |      some cases.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |  \n",
      " |  min_samples_split : int, float, optional (default=2)\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a fraction and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int, float, optional (default=1)\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a fraction and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, optional (default=0.)\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_depth : integer, optional (default=3)\n",
      " |      maximum depth of the individual regression estimators. The maximum\n",
      " |      depth limits the number of nodes in the tree. Tune this parameter\n",
      " |      for best performance; the best value depends on the interaction\n",
      " |      of the input variables.\n",
      " |  \n",
      " |  min_impurity_decrease : float, optional (default=0.)\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  min_impurity_split : float, (default=1e-7)\n",
      " |      Threshold for early stopping in tree growth. A node will split\n",
      " |      if its impurity is above the threshold, otherwise it is a leaf.\n",
      " |  \n",
      " |      .. deprecated:: 0.19\n",
      " |         ``min_impurity_split`` has been deprecated in favor of\n",
      " |         ``min_impurity_decrease`` in 0.19. The default value of\n",
      " |         ``min_impurity_split`` will change from 1e-7 to 0 in 0.23 and it\n",
      " |         will be removed in 0.25. Use ``min_impurity_decrease`` instead.\n",
      " |  \n",
      " |  init : estimator or 'zero', optional (default=None)\n",
      " |      An estimator object that is used to compute the initial predictions.\n",
      " |      ``init`` has to provide `fit` and `predict_proba`. If 'zero', the\n",
      " |      initial raw predictions are set to zero. By default, a\n",
      " |      ``DummyEstimator`` predicting the classes priors is used.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional (default=None)\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`.\n",
      " |  \n",
      " |  max_features : int, float, string or None, optional (default=None)\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |      - If int, then consider `max_features` features at each split.\n",
      " |      - If float, then `max_features` is a fraction and\n",
      " |        `int(max_features * n_features)` features are considered at each\n",
      " |        split.\n",
      " |      - If \"auto\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |      - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Choosing `max_features < n_features` leads to a reduction of variance\n",
      " |      and an increase in bias.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  verbose : int, default: 0\n",
      " |      Enable verbose output. If 1 then it prints progress and performance\n",
      " |      once in a while (the more trees the lower the frequency). If greater\n",
      " |      than 1 then it prints progress and performance for every tree.\n",
      " |  \n",
      " |  max_leaf_nodes : int or None, optional (default=None)\n",
      " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  warm_start : bool, default: False\n",
      " |      When set to ``True``, reuse the solution of the previous call to fit\n",
      " |      and add more estimators to the ensemble, otherwise, just erase the\n",
      " |      previous solution. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  presort : bool or 'auto', optional (default='auto')\n",
      " |      Whether to presort the data to speed up the finding of best splits in\n",
      " |      fitting. Auto mode by default will use presorting on dense data and\n",
      " |      default to normal sorting on sparse data. Setting presort to true on\n",
      " |      sparse data will raise an error.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *presort* parameter.\n",
      " |  \n",
      " |  validation_fraction : float, optional, default 0.1\n",
      " |      The proportion of training data to set aside as validation set for\n",
      " |      early stopping. Must be between 0 and 1.\n",
      " |      Only used if ``n_iter_no_change`` is set to an integer.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  n_iter_no_change : int, default None\n",
      " |      ``n_iter_no_change`` is used to decide if early stopping will be used\n",
      " |      to terminate training when validation score is not improving. By\n",
      " |      default it is set to None to disable early stopping. If set to a\n",
      " |      number, it will set aside ``validation_fraction`` size of the training\n",
      " |      data as validation and terminate training when validation score is not\n",
      " |      improving in all of the previous ``n_iter_no_change`` numbers of\n",
      " |      iterations. The split is stratified.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  tol : float, optional, default 1e-4\n",
      " |      Tolerance for the early stopping. When the loss is not improving\n",
      " |      by at least tol for ``n_iter_no_change`` iterations (if set to a\n",
      " |      number), the training stops.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  n_estimators_ : int\n",
      " |      The number of estimators as selected by early stopping (if\n",
      " |      ``n_iter_no_change`` is specified). Otherwise it is set to\n",
      " |      ``n_estimators``.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  feature_importances_ : array, shape (n_features,)\n",
      " |      The feature importances (the higher, the more important the feature).\n",
      " |  \n",
      " |  oob_improvement_ : array, shape (n_estimators,)\n",
      " |      The improvement in loss (= deviance) on the out-of-bag samples\n",
      " |      relative to the previous iteration.\n",
      " |      ``oob_improvement_[0]`` is the improvement in\n",
      " |      loss of the first stage over the ``init`` estimator.\n",
      " |  \n",
      " |  train_score_ : array, shape (n_estimators,)\n",
      " |      The i-th score ``train_score_[i]`` is the deviance (= loss) of the\n",
      " |      model at iteration ``i`` on the in-bag sample.\n",
      " |      If ``subsample == 1`` this is the deviance on the training data.\n",
      " |  \n",
      " |  loss_ : LossFunction\n",
      " |      The concrete ``LossFunction`` object.\n",
      " |  \n",
      " |  init_ : estimator\n",
      " |      The estimator that provides the initial predictions.\n",
      " |      Set via the ``init`` argument or ``loss.init_estimator``.\n",
      " |  \n",
      " |  estimators_ : ndarray of DecisionTreeRegressor,shape (n_estimators, ``loss_.K``)\n",
      " |      The collection of fitted sub-estimators. ``loss_.K`` is 1 for binary\n",
      " |      classification, otherwise n_classes.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data and\n",
      " |  ``max_features=n_features``, if the improvement of the criterion is\n",
      " |  identical for several splits enumerated during the search of the best\n",
      " |  split. To obtain a deterministic behaviour during fitting,\n",
      " |  ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  sklearn.ensemble.HistGradientBoostingClassifier,\n",
      " |  sklearn.tree.DecisionTreeClassifier, RandomForestClassifier\n",
      " |  AdaBoostClassifier\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  J. Friedman, Greedy Function Approximation: A Gradient Boosting\n",
      " |  Machine, The Annals of Statistics, Vol. 29, No. 5, 2001.\n",
      " |  \n",
      " |  J. Friedman, Stochastic Gradient Boosting, 1999\n",
      " |  \n",
      " |  T. Hastie, R. Tibshirani and J. Friedman.\n",
      " |  Elements of Statistical Learning Ed. 2, Springer, 2009.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GradientBoostingClassifier\n",
      " |      BaseGradientBoosting\n",
      " |      sklearn.ensemble.base.BaseEnsemble\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.MetaEstimatorMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, presort='auto', validation_fraction=0.1, n_iter_no_change=None, tol=0.0001)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Compute the decision function of ``X``.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : array, shape (n_samples, n_classes) or (n_samples,)\n",
      " |          The decision function of the input samples, which corresponds to\n",
      " |          the raw values predicted from the trees of the ensemble . The\n",
      " |          order of the classes corresponds to that in the attribute\n",
      " |          `classes_`. Regression and binary classification produce an\n",
      " |          array of shape [n_samples].\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class for X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array, shape (n_samples,)\n",
      " |          The predicted values.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict class log-probabilities for X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AttributeError\n",
      " |          If the ``loss`` does not support probabilities.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array, shape (n_samples, n_classes)\n",
      " |          The class log-probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Predict class probabilities for X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Raises\n",
      " |      ------\n",
      " |      AttributeError\n",
      " |          If the ``loss`` does not support probabilities.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : array, shape (n_samples, n_classes)\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |  \n",
      " |  staged_decision_function(self, X)\n",
      " |      Compute decision function of ``X`` for each iteration.\n",
      " |      \n",
      " |      This method allows monitoring (i.e. determine error on testing set)\n",
      " |      after each stage.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : generator of array, shape (n_samples, k)\n",
      " |          The decision function of the input samples, which corresponds to\n",
      " |          the raw values predicted from the trees of the ensemble . The\n",
      " |          classes corresponds to that in the attribute `classes_`.\n",
      " |          Regression and binary classification are special cases with\n",
      " |          ``k == 1``, otherwise ``k==n_classes``.\n",
      " |  \n",
      " |  staged_predict(self, X)\n",
      " |      Predict class at each stage for X.\n",
      " |      \n",
      " |      This method allows monitoring (i.e. determine error on testing set)\n",
      " |      after each stage.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : generator of array of shape (n_samples,)\n",
      " |          The predicted value of the input samples.\n",
      " |  \n",
      " |  staged_predict_proba(self, X)\n",
      " |      Predict class probabilities at each stage for X.\n",
      " |      \n",
      " |      This method allows monitoring (i.e. determine error on testing set)\n",
      " |      after each stage.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : generator of array of shape (n_samples,)\n",
      " |          The predicted value of the input samples.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseGradientBoosting:\n",
      " |  \n",
      " |  apply(self, X)\n",
      " |      Apply trees in the ensemble to X, return leaf indices.\n",
      " |      \n",
      " |      .. versionadded:: 0.17\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          The input samples. Internally, its dtype will be converted to\n",
      " |          ``dtype=np.float32``. If a sparse matrix is provided, it will\n",
      " |          be converted to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array-like, shape (n_samples, n_estimators, n_classes)\n",
      " |          For each datapoint x in X and for each tree in the ensemble,\n",
      " |          return the index of the leaf x ends up in each estimator.\n",
      " |          In the case of binary classification n_classes is 1.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None, monitor=None)\n",
      " |      Fit the gradient boosting model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target values (strings or integers in classification, real numbers\n",
      " |          in regression)\n",
      " |          For classification, labels must correspond to classes.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,) or None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. In the case of\n",
      " |          classification, splits are also ignored if they would result in any\n",
      " |          single class carrying a negative weight in either child node.\n",
      " |      \n",
      " |      monitor : callable, optional\n",
      " |          The monitor is called after each iteration with the current\n",
      " |          iteration, a reference to the estimator and the local variables of\n",
      " |          ``_fit_stages`` as keyword arguments ``callable(i, self,\n",
      " |          locals())``. If the callable returns ``True`` the fitting procedure\n",
      " |          is stopped. The monitor can be used for various things such as\n",
      " |          computing held-out estimates, early stopping, model introspect, and\n",
      " |          snapshoting.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseGradientBoosting:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Return the feature importances (the higher, the more important the\n",
      " |         feature).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : array, shape (n_features,)\n",
      " |          The values of this array sum to 1, unless all trees are single node\n",
      " |          trees consisting of only the root node, in which case it will be an\n",
      " |          array of zeros.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.ensemble.base.BaseEnsemble:\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Returns the index'th estimator in the ensemble.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Returns iterator over estimators in the ensemble.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Returns the number of estimators in the ensemble.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
